# Document Embedding and Similarity Search

## Overview

This project demonstrates a pipeline for extracting text from PDF documents, generating embeddings for the extracted text, and performing semantic search to find the most similar chunks of text. 

## Document Representation Method

We use a chunking approach to represent the text from PDF documents. The `TextExtraction` class handles extracting text from PDFs and splitting it into chunks of a specified size (e.g., 1000 characters). Each chunk is then converted into an embedding using the `TextEmbedding` class.

## Similarity Metric

For similarity search, we use semantic search with embeddings generated by the `TextEmbedding` class. The `SimilaritySearch` class performs the search by comparing the semantic similarity of the extracted text from the query against the precomputed embeddings.

## Instructions

### Setup

1. **Install Dependencies**: Ensure you have all the required libraries installed. You can use the provided `requirements.txt` file or manually install the dependencies.

    ```bash
    pip install -r requirements.txt
    ```

2. **Prepare Data**: Place your PDF files in the `train` directory. Update the `filenames` list in the `train()` function with the paths to your PDF files.

### Running the Code

1. **Train the Model**:
    - The `train()` function extracts text from the specified PDFs, chunks the text, generates embeddings for each chunk, and returns these embeddings.

    ```python
    filenames = ['train/invoice_77073.pdf','train/Faller_8.pdf','train/invoice.pdf','train/2024.03.15_1145.pdf']
    text = TextExtraction(filenames)

    extracted_text = text.extract_text_from_pdf()

    chunk_text = text.chunk_text(extracted_text,1000)
    text_embedding = TextEmbedding()
    embeddings = text_embedding.generate_embeddings(chunk_text)
    return embeddings
    ```

2. **Perform Search**:
    - After training, you can perform a similarity search with a specific PDF by extracting text from the PDF and using the precomputed embeddings to find the most similar chunks.

    ```python
    text = TextExtraction(['train/invoice.pdf'])
    extracted_text = text.extract_text_from_pdf()
    search = SimilaritySearch()
    results = search.semantic_search(extracted_text, embeddings, 10)
    ```

    - Print the search results:

    ```python
    for result in results:
        print(f"Text: {result['text']}")
        print(f"Score: {result['score']}")
        print()
    ```
3. **Sample Code**:
```python
from utils.text_embedding import TextEmbedding
from utils.text_extraction import TextExtraction
from utils.similarity_search import SimilaritySearch

def train():
    filenames = ['train/invoice_77073.pdf','train/Faller_8.pdf','train/invoice.pdf','train/2024.03.15_1145.pdf']
    text = TextExtraction(filenames)

    extracted_text = text.extract_text_from_pdf()

    chunk_text = text.chunk_text(extracted_text,1000)
    text_embedding = TextEmbedding()
    embeddings = text_embedding.generate_embeddings(chunk_text)
    return embeddings

embeddings = train()

# test

text = TextExtraction(['train/invoice.pdf'])

extracted_text = text.extract_text_from_pdf()

print(f"Extracted Invoice {extracted_text}")
search = SimilaritySearch()
results = search.semantic_search(extracted_text, embeddings, 10)

for result in results:
    print(f"Text: {result['text']}")
    print(f"Score: {result['score']}")
    print()
```
- **`topN` Parameter**: Specifies the number of top similar results to return from the search. For example, `topN=10` will return the top 10 most similar chunks.
### Files

- `utils/text_embedding.py`: Contains the `TextEmbedding` class for generating embeddings.
- `utils/text_extraction.py`: Contains the `TextExtraction` class for extracting and chunking text from PDFs.
- `utils/similarity_search.py`: Contains the `SimilaritySearch` class for performing semantic search.

### Notes

- Ensure the PDF files are correctly formatted and readable.
- Adjust chunk size in the `chunk_text` method if needed to optimize performance.

## License

There is no license in this project.

